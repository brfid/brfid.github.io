[{"content":"Most LLM coding assistants have no memory between sessions. You reload the conversation, re-explain the project, re-establish context, and hope the model picks up where you left off. The standard workaround — a large CLAUDE.md or AGENTS.md with everything in it — breaks down quickly. It turns static context into a dumping ground, grows without discipline, and gives the model no signal about what\u0026rsquo;s currently changing.\nThe fix I landed on is simple: treat CHANGELOG.md [Unreleased] as the primary mutable state document.\nWhy it works Keep a Changelog defines a format most LLMs recognize on sight: a fenced [Unreleased] block at the top, dated releases below. LLMs understand the convention without being told. They know [Unreleased] is active work and dated entries are history.\nThat maps directly onto what you need for session continuity:\n[Unreleased] — mutable, updated every session. Current state, active priorities, blockers, decisions pending. The model reads this first. Dated entries — append-only history. Evidence that decisions happened and why. The model reads these to reconstruct context if it needs depth. The AGENTS.md (or CLAUDE.md) file becomes stable configuration: conventions, file paths, source-of-truth map. It changes rarely. The CHANGELOG absorbs the churn.\nThe session start instruction One line at the top of AGENTS.md is enough:\nRead CHANGELOG.md [Unreleased] at session start. From there the model knows where it is, what\u0026rsquo;s in flight, and what to do next. No re-explanation needed.\nWhat goes in [Unreleased] I use explicit subsections:\n## [Unreleased] ### Current State One-paragraph snapshot. Where things stand right now. ### Active Priorities Ordered list of what needs to happen next. ### In Progress What the model started in the current session. ### Blocked Anything waiting on external action. ### Decisions Needed Open questions the model should surface, not resolve unilaterally. ### Recently Completed What just shipped. Moves to a dated entry on the next commit. The model updates [Unreleased] at the end of each session. The next session reads it cold and picks up cleanly.\nWhat this is not This is not a replacement for good project documentation. Architectural decisions, integration details, and source-of-truth maps still belong in stable docs. The changelog is the session state layer, not the full context layer.\nIt also does not solve the problem of context window limits on large projects. It reduces the cost of context: the model loads a small, structured, current-state document instead of scanning a stale megafile.\nResult Sessions are shorter to start, more reliable to hand off, and easier to audit. The changelog does the work it was always supposed to do — track what changed and when — and the LLM does less redundant orientation work each time.\nThe format is well-understood, self-describing, and version-controlled. It costs nothing to adopt if you are already using Keep a Changelog.\n","permalink":"https://www.jockeyholler.net/posts/changelog-as-llm-memory/","summary":"\u003cp\u003eMost LLM coding assistants have no memory between sessions. You reload the conversation,\nre-explain the project, re-establish context, and hope the model picks up where you left off.\nThe standard workaround — a large \u003ccode\u003eCLAUDE.md\u003c/code\u003e or \u003ccode\u003eAGENTS.md\u003c/code\u003e with everything in it — breaks\ndown quickly. It turns static context into a dumping ground, grows without discipline, and\ngives the model no signal about what\u0026rsquo;s \u003cem\u003ecurrently\u003c/em\u003e changing.\u003c/p\u003e\n\u003cp\u003eThe fix I landed on is simple: treat \u003ccode\u003eCHANGELOG.md [Unreleased]\u003c/code\u003e as the primary mutable\nstate document.\u003c/p\u003e","title":"Using CHANGELOG.md as LLM session memory"},{"content":"Senior technical writer. I work on documentation platforms, AI-assisted authoring workflows, and the engineering side of content delivery.\nThis site is jockeyholler.net — a colonial-era name for the neighborhood where I live, known mostly to local historians.\nLinkedIn GitHub brad@jockeyholler.net ","permalink":"https://www.jockeyholler.net/about/","summary":"About Bradley Fidler","title":"About"}]