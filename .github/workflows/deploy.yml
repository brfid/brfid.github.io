name: Publish Site

# Mode 1: Fast local publish tags
# Mode 2: Distributed vintage publish tags (VAX build host + PDP-11 validation)

on:
  push:
    tags:
      - "publish-vintage"     # Mode 2: Distributed vintage pipeline
      - "publish-vintage-*"   # Mode 2: Distributed vintage variants
      - "publish-vax"         # Mode 2 legacy alias
      - "publish-vax-*"       # Mode 2 legacy alias
      - "publish-docker"      # Mode 2 legacy alias
      - "publish-docker-*"    # Mode 2 legacy alias
      - "publish"           # Mode 1: Fast (local)
      - "publish-fast"      # Mode 1: Fast (explicit)
      - "publish-fast-*"    # Mode 1: Fast variants
  workflow_dispatch:
    inputs:
      build_mode:
        description: 'Build mode (local or distributed vintage backend)'
        required: true
        default: 'local'
        type: choice
        options:
          - local
          - docker

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: "pyproject.toml"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e '.[dev]'

      - name: Quality checks
        run: |
          # Keep publish checks aligned with CI/test policy to avoid unrelated
          # full-repo lint/type failures during deployment runs.
          python -m ruff check resume_generator
          python -m mypy resume_generator host_logging tests
          python -m pytest -q -m "unit and not docker and not slow"
          python -m pylint resume_generator -sn
          python -m vulture --config pyproject.toml resume_generator

      - name: Determine build mode
        id: mode
        run: |
          # Determine mode based on tag name
          TAG_NAME="${{ github.ref_name }}"

          if [[ "$TAG_NAME" == *"vax"* ]] || [[ "$TAG_NAME" == *"docker"* ]] || [[ "$TAG_NAME" == *"vintage"* ]] || [[ "$TAG_NAME" == *"distributed"* ]]; then
            echo "build_mode=docker" >> $GITHUB_OUTPUT
            echo "mode_name=Distributed vintage (authentic build)" >> $GITHUB_OUTPUT
            echo "ðŸš€ Building with distributed vintage mode (authentic BSD pipeline)"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "build_mode=${{ inputs.build_mode }}" >> $GITHUB_OUTPUT
            echo "mode_name=Manual (${{ inputs.build_mode }})" >> $GITHUB_OUTPUT
            echo "ðŸŽ® Building with manual mode: ${{ inputs.build_mode }}"
          else
            echo "build_mode=local" >> $GITHUB_OUTPUT
            echo "mode_name=Local (fast)" >> $GITHUB_OUTPUT
            echo "âš¡ Building with local mode (fast)"
          fi

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install Playwright browsers
        run: python -m playwright install --with-deps chromium

      - name: Generate build ID
        if: steps.mode.outputs.build_mode == 'docker'
        id: build_id
        run: |
          BUILD_ID="build-$(date -u '+%Y%m%d-%H%M%S')"
          echo "build_id=$BUILD_ID" >> $GITHUB_OUTPUT
          echo "ðŸ“ Build ID: $BUILD_ID"

      - name: Setup SSH key
        if: steps.mode.outputs.build_mode == 'docker'
        run: |
          echo "${{ secrets.AWS_SSH_PRIVATE_KEY }}" > /tmp/aws-key.pem
          chmod 600 /tmp/aws-key.pem

      - name: Activate AWS infrastructure
        if: steps.mode.outputs.build_mode == 'docker'
        id: aws_activate
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          ts() { date -u '+%Y-%m-%d %H:%M:%S'; }

          echo "[$(ts) GITHUB] AWS_ACTIVATE_BEGIN vax=${{ secrets.AWS_VAX_INSTANCE_ID }} pdp11=${{ secrets.AWS_PDP11_INSTANCE_ID }}" >> /tmp/github.log
          echo "ðŸš€ Starting AWS VAX and PDP-11 instances..."
          aws ec2 start-instances --instance-ids \
            ${{ secrets.AWS_VAX_INSTANCE_ID }} \
            ${{ secrets.AWS_PDP11_INSTANCE_ID }}

          echo "â³ Waiting for instances to be running..."
          aws ec2 wait instance-running --instance-ids \
            ${{ secrets.AWS_VAX_INSTANCE_ID }} \
            ${{ secrets.AWS_PDP11_INSTANCE_ID }}

          echo "ðŸ“¡ Getting instance IPs..."
          VAX_IP=$(aws ec2 describe-instances \
            --instance-ids ${{ secrets.AWS_VAX_INSTANCE_ID }} \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)
          PDP11_IP=$(aws ec2 describe-instances \
            --instance-ids ${{ secrets.AWS_PDP11_INSTANCE_ID }} \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)

          if [[ -z "$VAX_IP" || "$VAX_IP" == "None" || -z "$PDP11_IP" || "$PDP11_IP" == "None" ]]; then
            echo "âŒ Failed to resolve AWS instance public IPs"
            echo "[$(ts) GITHUB] AWS_ACTIVATE_FAILED reason=missing_public_ip vax_ip=$VAX_IP pdp11_ip=$PDP11_IP" >> /tmp/github.log
            exit 1
          fi

          wait_for_ssh() {
            local name="$1"
            local ip="$2"
            local ready=0
            echo "â³ Waiting for SSH on $name ($ip)..."
            for i in {1..30}; do
              if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 -i /tmp/aws-key.pem "ubuntu@$ip" echo "ready" >/dev/null 2>&1; then
                ready=1
                echo "âœ… SSH ready on $name"
                break
              fi
              echo "Attempt $i/30: SSH not ready yet on $name..."
              sleep 10
            done
            if [[ "$ready" -ne 1 ]]; then
              echo "âŒ SSH readiness timeout for $name ($ip)"
              echo "[$(ts) GITHUB] AWS_ACTIVATE_FAILED reason=ssh_timeout host=$name ip=$ip" >> /tmp/github.log
              exit 1
            fi
          }

          wait_for_ssh "VAX" "$VAX_IP"
          wait_for_ssh "PDP11" "$PDP11_IP"

          echo "vax_ip=$VAX_IP" >> $GITHUB_OUTPUT
          echo "pdp11_ip=$PDP11_IP" >> $GITHUB_OUTPUT
          echo "[$(ts) GITHUB] AWS_ACTIVATE_READY vax_ip=$VAX_IP pdp11_ip=$PDP11_IP" >> /tmp/github.log
          echo "âœ… AWS infrastructure activated"

      - name: Transfer scripts to AWS
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          VAX_IP: ${{ steps.aws_activate.outputs.vax_ip }}
          PDP11_IP: ${{ steps.aws_activate.outputs.pdp11_ip }}
        run: |
          echo "ðŸ“¤ Transferring scripts to AWS instances..."

          # Transfer to VAX
          scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
            scripts/arpanet-log.sh \
            scripts/vax-build-and-encode.sh \
            scripts/merge-logs.py \
            scripts/extract-vax-logs.py \
            scripts/extract-pdp11-logs.py \
            ubuntu@$VAX_IP:/tmp/

          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
            'chmod +x /tmp/*.sh /tmp/*.py'

          # Transfer to PDP-11
          scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
            scripts/arpanet-log.sh \
            ubuntu@$PDP11_IP:/tmp/

          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$PDP11_IP \
            'chmod +x /tmp/*.sh'

          echo "âœ… Scripts transferred to both instances"

      - name: Stage 1 - VAX Build & Encode
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          VAX_IP: ${{ steps.aws_activate.outputs.vax_ip }}
          BUILD_ID: ${{ steps.build_id.outputs.build_id }}
        run: |
          echo "=== STAGE 1: VAX BUILD & ENCODE ==="
          echo "VAX IP: $VAX_IP"
          echo "Build ID: $BUILD_ID"

          # Log GitHub Actions activity
          exec > >(tee >(while IFS= read -r line; do echo "[$(date -u '+%Y-%m-%d %H:%M:%S') GITHUB] $line"; done >> /tmp/github.log)) 2>&1

          # Generate resume.vax.yaml locally
          echo "Generating resume.vax.yaml locally..."
          python -m resume_generator --out site --with-vax --vax-mode local

          # Install screen for console automation
          if ! command -v screen &> /dev/null; then
            echo "Installing screen..."
            sudo apt-get update -qq
            sudo apt-get install -y screen
          fi

          # Upload arpanet-log.sh to VAX BSD via console
          echo "Uploading arpanet-log.sh to VAX BSD..."
          bash scripts/vax-console-upload.sh scripts/arpanet-log.sh /tmp/arpanet-log.sh "$VAX_IP"

          # Make it executable inside BSD
          SESSION="vax-chmod-$$"
          screen -dmS "$SESSION" telnet "$VAX_IP" 2323
          sleep 3
          screen -S "$SESSION" -X stuff "\n"
          sleep 0.5
          screen -S "$SESSION" -X stuff "root\n"
          sleep 2
          screen -S "$SESSION" -X stuff "chmod +x /tmp/arpanet-log.sh\n"
          sleep 1
          screen -S "$SESSION" -X quit 2>/dev/null || true

          # Upload source files to VAX BSD via console
          echo "Uploading bradman.c to VAX BSD..."
          bash scripts/vax-console-upload.sh vax/bradman.c /tmp/bradman.c "$VAX_IP"

          echo "Uploading resume.vax.yaml to VAX BSD..."
          bash scripts/vax-console-upload.sh build/vax/resume.vax.yaml /tmp/resume.vax.yaml "$VAX_IP"

          # Upload build script to VAX BSD via console
          echo "Uploading vax-build-and-encode.sh to VAX BSD..."
          bash scripts/vax-console-upload.sh scripts/vax-build-and-encode.sh /tmp/vax-build-and-encode.sh "$VAX_IP"

          # Make build script executable inside BSD
          screen -dmS "$SESSION" telnet "$VAX_IP" 2323
          sleep 3
          screen -S "$SESSION" -X stuff "\n"
          sleep 0.5
          screen -S "$SESSION" -X stuff "root\n"
          sleep 2
          screen -S "$SESSION" -X stuff "chmod +x /tmp/vax-build-and-encode.sh\n"
          sleep 1
          screen -S "$SESSION" -X quit 2>/dev/null || true

          # Execute build script INSIDE VAX BSD
          echo "Executing build inside VAX BSD (vintage K&R C)..."
          SESSION="vax-build-$$"
          screen -dmS "$SESSION" telnet "$VAX_IP" 2323
          sleep 3
          screen -S "$SESSION" -X stuff "\n"
          sleep 0.5
          screen -S "$SESSION" -X stuff "root\n"
          sleep 2
          screen -S "$SESSION" -X stuff "cd /tmp\n"
          sleep 1
          screen -S "$SESSION" -X stuff "/tmp/vax-build-and-encode.sh $BUILD_ID\n"

          # Wait for build to complete (adjust timing as needed)
          echo "Waiting for build to complete..."
          sleep 30

          # Capture console output
          screen -S "$SESSION" -X hardcopy "/tmp/vax-build-console.txt"
          screen -S "$SESSION" -X quit 2>/dev/null || true

          # Extract logs from console capture
          echo "Extracting logs from console output..."

          if [ -f /tmp/vax-build-console.txt ]; then
            # Verify build succeeded
            if grep -q "VAX build complete" /tmp/vax-build-console.txt; then
              echo "âœ“ Build succeeded (verified via console)"

              # Upload console capture to container for processing
              scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
                /tmp/vax-build-console.txt \
                ubuntu@$VAX_IP:/tmp/vax-build-console.txt

              # Extract logs from console capture to EFS
              ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
                "mkdir -p /mnt/arpanet-logs/builds/$BUILD_ID && \
                 python3 /tmp/extract-vax-logs.py \
                   /tmp/vax-build-console.txt \
                   /mnt/arpanet-logs/builds/$BUILD_ID/VAX.log"

              echo "âœ“ Logs extracted to EFS"
            else
              echo "âš ï¸  Build status unclear from console output"
              echo "Console output (last 50 lines):"
              tail -50 /tmp/vax-build-console.txt
            fi
          else
            echo "âš ï¸  Console capture not found"
          fi

          echo "âœ“ VAX build & encode complete (executed in BSD with vintage tools)"

      - name: Stage 2 - Console Transfer (VAX â†’ PDP-11)
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          VAX_IP: ${{ steps.aws_activate.outputs.vax_ip }}
          PDP11_IP: ${{ steps.aws_activate.outputs.pdp11_ip }}
          BUILD_ID: ${{ steps.build_id.outputs.build_id }}
        run: |
          echo "=== STAGE 2: CONSOLE TRANSFER ==="
          echo "VAX IP: $VAX_IP"
          echo "PDP-11 IP: $PDP11_IP"
          echo "Build ID: $BUILD_ID"

          # Retrieve encoded file from VAX BSD via console cat
          echo "Retrieving encoded file from VAX BSD..."
          SESSION="vax-retrieve-$$"
          screen -dmS "$SESSION" telnet "$VAX_IP" 2323
          sleep 3
          screen -S "$SESSION" -X stuff "\n"
          sleep 0.5
          screen -S "$SESSION" -X stuff "root\n"
          sleep 2
          screen -S "$SESSION" -X stuff "cat /tmp/brad.1.uu\n"
          sleep 5
          screen -S "$SESSION" -X hardcopy "/tmp/vax-cat-output.txt"
          screen -S "$SESSION" -X quit 2>/dev/null || true

          # Extract just the uuencoded content (skip prompts)
          grep -E '^(begin|M|end)' /tmp/vax-cat-output.txt > /tmp/brad.1.uu || echo "Warning: Could not extract uuencoded file"

          # Verify we got the file
          if [ -f /tmp/brad.1.uu ] && [ -s /tmp/brad.1.uu ]; then
            echo "âœ“ Retrieved brad.1.uu ($(wc -l < /tmp/brad.1.uu) lines)"
          else
            echo "âŒ Failed to retrieve brad.1.uu from VAX BSD"
            exit 1
          fi

          # Upload arpanet-log.sh to PDP-11 BSD
          echo "Uploading arpanet-log.sh to PDP-11 BSD..."

          # Create a console upload helper for PDP-11
          SESSION="pdp11-upload-$$"
          screen -dmS "$SESSION" telnet "$PDP11_IP" 2327
          sleep 3
          screen -S "$SESSION" -X stuff "\n"
          sleep 0.5
          screen -S "$SESSION" -X stuff "root\n"
          sleep 2

          # Upload arpanet-log.sh via heredoc
          screen -S "$SESSION" -X stuff "cat > /tmp/arpanet-log.sh << 'UPLOAD_EOF'\n"
          sleep 0.5

          while IFS= read -r line; do
            screen -S "$SESSION" -X stuff "$line\r"
            sleep 0.02
          done < scripts/arpanet-log.sh

          screen -S "$SESSION" -X stuff "UPLOAD_EOF\n"
          sleep 1
          screen -S "$SESSION" -X stuff "chmod +x /tmp/arpanet-log.sh\n"
          sleep 1
          screen -S "$SESSION" -X quit 2>/dev/null || true

          echo "âœ“ arpanet-log.sh uploaded to PDP-11 BSD"

          # Run console transfer
          echo "Starting console transfer to PDP-11..."
          python3 scripts/console-transfer.py "$BUILD_ID" "$VAX_IP" "$PDP11_IP"

          echo "âœ“ Console transfer complete"

      - name: Verify screen session persists
        if: steps.mode.outputs.build_mode == 'docker'
        run: |
          echo "ðŸ“¡ Verifying screen session..."
          if screen -ls | grep -q "pdp11-console"; then
            echo "âœ… Screen session 'pdp11-console' is active"
            screen -ls
          else
            echo "âŒ Screen session 'pdp11-console' not found"
            echo "Available sessions:"
            screen -ls || echo "No screen sessions found"
            echo "Processes:"
            ps aux | grep screen || true
            exit 1
          fi

      - name: Stage 3 - PDP-11 Validation
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          BUILD_ID: ${{ steps.build_id.outputs.build_id }}
          PDP11_IP: ${{ steps.aws_activate.outputs.pdp11_ip }}
          VAX_IP: ${{ steps.aws_activate.outputs.vax_ip }}
        run: |
          echo "=== STAGE 3: PDP-11 VALIDATION ==="
          echo "Build ID: $BUILD_ID"
          echo "PDP-11 IP: $PDP11_IP"

          # Run validation commands on PDP-11 console
          echo "Sending validation commands to PDP-11..."
          bash scripts/pdp11-validate.sh "$BUILD_ID"

          # Extract logs from PDP-11 console capture
          echo "Extracting PDP-11 logs from console output..."

          if [ -f /tmp/pdp11-validation-$BUILD_ID.txt ]; then
            # Verify validation succeeded
            if grep -q "Status: PASS" /tmp/pdp11-validation-$BUILD_ID.txt; then
              echo "âœ“ Validation succeeded (verified via console)"

              # Upload console capture to container for processing
              scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
                /tmp/pdp11-validation-$BUILD_ID.txt \
                ubuntu@$VAX_IP:/tmp/pdp11-validation-$BUILD_ID.txt

              # Extract logs from console capture to EFS (using VAX container which has EFS mounted)
              ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
                "mkdir -p /mnt/arpanet-logs/builds/$BUILD_ID && \
                 python3 /tmp/extract-pdp11-logs.py \
                   /tmp/pdp11-validation-$BUILD_ID.txt \
                   /mnt/arpanet-logs/builds/$BUILD_ID/PDP11.log"

              echo "âœ“ PDP-11 logs extracted to EFS"
            else
              echo "âš ï¸  Validation status unclear from console output"
              echo "Console output (last 50 lines):"
              tail -50 /tmp/pdp11-validation-$BUILD_ID.txt
            fi
          else
            echo "âš ï¸  PDP-11 console capture not found"
          fi

          echo "âœ“ PDP-11 validation complete"

      - name: Stage 4 - Retrieve Final Output
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          VAX_IP: ${{ steps.aws_activate.outputs.vax_ip }}
          BUILD_ID: ${{ steps.build_id.outputs.build_id }}
        run: |
          echo "=== STAGE 4: RETRIEVE FINAL OUTPUT ==="

          # Retrieve validated output from PDP-11 via EFS (mounted on VAX)
          echo "Retrieving validated output from PDP-11..."
          scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
            ubuntu@$VAX_IP:/mnt/arpanet-logs/builds/$BUILD_ID/pdp-output/brad.txt \
            build/vax/brad.txt || echo "Warning: brad.txt not found, using original"

          # Fallback: if PDP-11 output not available, get from VAX
          if [[ ! -f build/vax/brad.txt ]]; then
            echo "Using VAX original output..."
            scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
              ubuntu@$VAX_IP:/tmp/brad.1 \
              build/vax/brad.1
            python -m resume_generator.manpage --in build/vax/brad.1 --out build/vax/brad.txt
          fi

          # Copy to site
          cp build/vax/brad.txt site/brad.man.txt

          echo "âœ“ Final output retrieved"

      - name: Generate site (Local mode fallback)
        if: steps.mode.outputs.build_mode != 'docker'
        run: |
          python -m resume_generator --out site --with-vax \
            --vax-mode ${{ steps.mode.outputs.build_mode }}

      - name: Merge and retrieve build logs
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          VAX_IP: ${{ steps.aws_activate.outputs.vax_ip }}
          BUILD_ID: ${{ steps.build_id.outputs.build_id }}
        run: |
          echo "ðŸ“‹ Merging build logs from all sources..."

          # Ensure build directory exists on EFS
          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
            "mkdir -p /mnt/arpanet-logs/builds/$BUILD_ID"

          # Upload GitHub log to VAX (for EFS)
          if [[ -f /tmp/github.log ]]; then
            echo "Uploading GitHub Actions log to EFS..."
            scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
              /tmp/github.log \
              ubuntu@$VAX_IP:/mnt/arpanet-logs/builds/$BUILD_ID/GITHUB.log
          fi

          # Upload COURIER log to VAX (for EFS)
          if [[ -f /tmp/COURIER-$BUILD_ID.log ]]; then
            echo "Uploading COURIER log to EFS..."
            scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
              /tmp/COURIER-$BUILD_ID.log \
              ubuntu@$VAX_IP:/mnt/arpanet-logs/builds/$BUILD_ID/COURIER.log
          fi

          # Verify all log sources exist
          echo "Checking log sources..."
          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
            "ls -lh /mnt/arpanet-logs/builds/$BUILD_ID/*.log"

          # Merge logs chronologically (VAX, PDP11, COURIER, GITHUB)
          echo "Merging logs chronologically..."
          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
            "python3 /tmp/merge-logs.py $BUILD_ID"

          # Retrieve all logs
          echo "Retrieving build logs..."
          mkdir -p site/build-logs

          # Retrieve merged log
          scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
            ubuntu@$VAX_IP:/mnt/arpanet-logs/builds/$BUILD_ID/merged.log \
            site/build-logs/merged.log

          # Retrieve individual component logs
          for component in VAX PDP11 COURIER GITHUB; do
            if ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
              "test -f /mnt/arpanet-logs/builds/$BUILD_ID/${component}.log"; then
              echo "Retrieving ${component}.log..."
              scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
                ubuntu@$VAX_IP:/mnt/arpanet-logs/builds/$BUILD_ID/${component}.log \
                site/build-logs/${component}.log
            else
              echo "Warning: ${component}.log not found"
            fi
          done

          # Cleanup old builds (keep last 20)
          echo "Cleaning up old builds on EFS..."
          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
            'cd /mnt/arpanet-logs/builds && ls -t | tail -n +21 | xargs -r rm -rf'

          echo "âœ… Logs merged and retrieved from all sources"

      - name: Generate enterprise logs page
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          BUILD_ID: ${{ steps.build_id.outputs.build_id }}
        run: |
          echo "ðŸ“„ Generating enterprise logs page..."

          python3 scripts/generate-logs-page.py \
            --build-id "$BUILD_ID" \
            --merged site/build-logs/merged.log \
            --output site/logs/index.html

          echo "âœ… Logs page generated at site/logs/index.html"

      - name: Generate build info widget
        if: steps.mode.outputs.build_mode == 'docker'
        env:
          VAX_IP: ${{ steps.aws_activate.outputs.vax_ip }}
          BUILD_ID: ${{ steps.build_id.outputs.build_id }}
        run: |
          echo "ðŸ“Š Generating build info widget..."

          # Transfer generate-build-info.py to VAX
          scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
            scripts/generate-build-info.py \
            ubuntu@$VAX_IP:/tmp/generate-build-info.py

          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
            'chmod +x /tmp/generate-build-info.py'

          # Generate build info on VAX
          ssh -o StrictHostKeyChecking=no -i /tmp/aws-key.pem ubuntu@$VAX_IP \
            "python3 /tmp/generate-build-info.py $BUILD_ID /mnt/arpanet-logs /tmp/build-info"

          # Retrieve generated files
          mkdir -p site/build-info
          scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
            ubuntu@$VAX_IP:/tmp/build-info/build-info.json \
            site/build-info/

          scp -o StrictHostKeyChecking=no -i /tmp/aws-key.pem \
            ubuntu@$VAX_IP:/tmp/build-info/build-info.html \
            site/build-info/

          # Copy CSS
          cp templates/build-info.css site/build-info/

          echo "âœ… Build info widget generated"

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Deactivate AWS infrastructure
        if: always() && steps.mode.outputs.build_mode == 'docker'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          ts() { date -u '+%Y-%m-%d %H:%M:%S'; }

          echo "[$(ts) GITHUB] AWS_DEACTIVATE_BEGIN vax=${{ secrets.AWS_VAX_INSTANCE_ID }} pdp11=${{ secrets.AWS_PDP11_INSTANCE_ID }}" >> /tmp/github.log
          echo "ðŸ›‘ Stopping AWS VAX and PDP-11 instances..."
          aws ec2 stop-instances --instance-ids \
            ${{ secrets.AWS_VAX_INSTANCE_ID }} \
            ${{ secrets.AWS_PDP11_INSTANCE_ID }} >/dev/null

          echo "â³ Waiting for instances to stop..."
          aws ec2 wait instance-stopped --instance-ids \
            ${{ secrets.AWS_VAX_INSTANCE_ID }} \
            ${{ secrets.AWS_PDP11_INSTANCE_ID }}

          echo "[$(ts) GITHUB] AWS_DEACTIVATE_COMPLETE" >> /tmp/github.log
          echo "âœ… AWS infrastructure deactivated (cost savings mode)"

      - name: Summary
        run: |
          echo "## âœ… Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Mode**: ${{ steps.mode.outputs.mode_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**URL**: ${{ steps.deployment.outputs.page_url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
